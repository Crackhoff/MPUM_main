{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook we use tensorflow CNN model to find waldo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from img_gen import create_sample\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "IMG_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating waldo images\n",
    "\n",
    "# create_sample(IMG_SIZE,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10337 files belonging to 2 classes.\n",
      "Using 8270 files for training.\n",
      "Using 2067 files for validation.\n",
      "['notwaldo', 'waldo']\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    '../data/selfmade',\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=123,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=32)\n",
    "\n",
    "print(test_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10337 files belonging to 2 classes.\n",
      "['notwaldo', 'waldo']\n"
     ]
    }
   ],
   "source": [
    "yesset = tf.keras.utils.image_dataset_from_directory(\n",
    "    '../data/selfmade/',\n",
    "    seed=123,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=32)\n",
    "\n",
    "print(yesset.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5337 files belonging to 1 classes.\n",
      "['notwaldo']\n"
     ]
    }
   ],
   "source": [
    "notset = tf.keras.utils.image_dataset_from_directory(\n",
    "    '../data/src1/notwaldo',\n",
    "    seed=123,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=32)\n",
    "\n",
    "print(notset.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Lambda, Resizing\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def get_conv(input_shape=(IMG_SIZE, IMG_SIZE, 3), filename=None):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "model = get_conv()\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Resizing(224,224))\n",
    "model2.add(ResNet50(include_top=False, weights='imagenet', input_shape=(224,224,3)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(1024, activation='relu'))\n",
    "model2.add(Dense(2, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 1085 elements\n",
      "Class 1: 982 elements\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "label_counter = Counter()\n",
    "\n",
    "# Iterate through the dataset\n",
    "for images, labels in test_ds:\n",
    "    # Convert the labels to numpy array if they are in tensor format\n",
    "    labels_np = labels.numpy()\n",
    "    \n",
    "    # Update the counter with the labels in the current batch\n",
    "    label_counter.update(labels_np)\n",
    "\n",
    "# Print the number of elements for each class\n",
    "for label, count in label_counter.items():\n",
    "    print(f\"Class {label}: {count} elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 11:31:53.339708: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [8270]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2024-06-09 11:31:53.339924: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [8270]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "/opt/anaconda3/envs/tf/lib/python3.10/site-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70/259 [=======>......................] - ETA: 1:25 - loss: 238.8833 - accuracy: 0.8955"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# both = yesset.concatenate(train_ds)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model2\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                 loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m      8\u001b[0m                 metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 10\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m history2 \u001b[38;5;241m=\u001b[39m model2\u001b[38;5;241m.\u001b[39mfit(train_ds, validation_data\u001b[38;5;241m=\u001b[39mtest_ds, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# both = yesset.concatenate(train_ds)\n",
    "model2.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_ds, validation_data=test_ds, epochs=5)\n",
    "history2 = model2.fit(train_ds, validation_data=test_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x33231b400>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 11:32:35.381170: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [10337]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2024-06-09 11:32:35.381410: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [10337]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 - 39s - loss: 0.0817 - accuracy: 0.9766 - 39s/epoch - 121ms/step\n",
      "65/65 - 8s - loss: 0.0793 - accuracy: 0.9758 - 8s/epoch - 119ms/step\n",
      "65/65 [==============================] - 8s 118ms/step\n",
      "[8.0424879e-04 9.9919575e-01]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loss, test_acc = model.evaluate(yesset, verbose=2)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_ds, verbose=2)\n",
    "\n",
    "predictions = model.predict(test_ds)\n",
    "\n",
    "print(predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('5_0_0.jpg', 'notwaldo'),\n",
       " ('5_0_1.jpg', 'waldo'),\n",
       " ('5_0_2.jpg', 'notwaldo'),\n",
       " ('5_0_3.jpg', 'notwaldo'),\n",
       " ('5_1_0.jpg', 'waldo'),\n",
       " ('5_1_2.jpg', 'notwaldo'),\n",
       " ('5_1_3.jpg', 'notwaldo'),\n",
       " ('5_2_0.jpg', 'notwaldo'),\n",
       " ('5_2_1.jpg', 'notwaldo'),\n",
       " ('5_2_2.jpg', 'notwaldo'),\n",
       " ('5_2_3.jpg', 'notwaldo'),\n",
       " ('5_3_0.jpg', 'notwaldo'),\n",
       " ('5_3_1.jpg', 'notwaldo'),\n",
       " ('5_3_2.jpg', 'notwaldo'),\n",
       " ('5_3_3.jpg', 'notwaldo')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "directory_path = f'../data/src1/{IMG_SIZE}'\n",
    "pref = \"5_\"\n",
    "filenames = [(f,'waldo') for f in os.listdir(directory_path+'/waldo') if f.startswith(pref)]+[(f, 'notwaldo') for f in os.listdir(directory_path+'/notwaldo') if f.startswith(pref)]\n",
    "filenames.sort()\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "correct=0\n",
    "incorrect=0\n",
    "incorrect_files=[]\n",
    "correct_files=[]\n",
    "# print(filenames)\n",
    "for fname, true in tqdm(filenames):\n",
    "    img = image.load_img(f'../data/src1/{IMG_SIZE}/{true}/{fname}', target_size=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Create a batch\n",
    "    img_array /= 255.0  # Normalize the image to match the training data\n",
    "    \n",
    "    # Predict the class\n",
    "    prediction = model.predict(img_array, verbose =0)\n",
    "    predicted_class = 'waldo' if prediction[0][0] < prediction[0][1] else 'notwaldo'\n",
    "    # if true == 'notwaldo':\n",
    "        # print(true, prediction)\n",
    "    \n",
    "    # Print the prediction\n",
    "    if predicted_class==true:\n",
    "        correct += 1\n",
    "        correct_files+=[f'../data/src1/{IMG_SIZE}/{true}/{fname}']\n",
    "    else:\n",
    "        incorrect_files+=[f'../data/src1/{IMG_SIZE}/{true}/{fname}']\n",
    "        incorrect += 1\n",
    "    # print(f'Predicted class: {predicted_class} with {prediction[0]}\\t{\"CORRECT\" if predicted_class == True else \"INCORRECT\"}')\n",
    "    \n",
    "    # Optionally, display the image\n",
    "    # plt.imshow(img)\n",
    "    # plt.title(f'Predicted: {predicted_class}')\n",
    "    # plt.show()\n",
    "print(correct, incorrect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waldo correct:  0  incorrect:  2\n",
      "Notwaldo correct:  8  incorrect:  5\n"
     ]
    }
   ],
   "source": [
    "counter =0\n",
    "for f in correct_files:\n",
    "    if f.startswith(f'../data/src1/{IMG_SIZE}/waldo'):\n",
    "        counter+=1\n",
    "counter2 =0\n",
    "for f in incorrect_files:\n",
    "    if f.startswith(f'../data/src1/{IMG_SIZE}/waldo'):\n",
    "        counter2+=1 \n",
    "\n",
    "print(\"Waldo correct: \",counter, \" incorrect: \", counter2)\n",
    "\n",
    "counter =0\n",
    "for f in correct_files:\n",
    "    if f.startswith(f'../data/src1/{IMG_SIZE}/notwaldo'):\n",
    "        counter+=1\n",
    "counter2 =0\n",
    "for f in incorrect_files:\n",
    "    if f.startswith(f'../data/src1/{IMG_SIZE}/notwaldo'):\n",
    "        counter2+=1 \n",
    "\n",
    "print(\"Notwaldo correct: \",counter, \" incorrect: \", counter2) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
